{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRXmYQcpLEaQ8eSjYQ1ihV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhardwaj2-6/Agnet_Techniques/blob/main/%233_custom_customer_support_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set environment"
      ],
      "metadata": {
        "id": "1saPRIQi9kY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a4aHSOue3zxc",
        "outputId": "064f435d-5ef6-44a8-96a9-f47871e8ae12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.56)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (7.34.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.13.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython) (75.2.0)\n",
            "Collecting jedi>=0.16 (from IPython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
            "Downloading langgraph-0.4.3-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.24.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, jedi, langgraph-sdk, groq, langgraph-checkpoint, langchain_groq, langgraph-prebuilt, langgraph\n",
            "Successfully installed groq-0.24.0 jedi-0.19.2 langchain_groq-0.3.2 langgraph-0.4.3 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 ormsgpack-1.9.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install  langgraph langchain langchain_groq langchain_core IPython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Dict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod"
      ],
      "metadata": {
        "id": "Vfa4UjMj98Wp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "llm = ChatGroq(model=\"gemma2-9b-it\",api_key=os.environ.get(\"GROQ_API_KEY\"),verbose=True)\n"
      ],
      "metadata": {
        "id": "j3uQHZ6F_Kcv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define State Structure"
      ],
      "metadata": {
        "id": "YnNX8n_4_mQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  query: str\n",
        "  category: str\n",
        "  sentiment: str\n",
        "  response: str\n"
      ],
      "metadata": {
        "id": "PBeSFTty_hU3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Node Functions\n"
      ],
      "metadata": {
        "id": "c8Tq8XiEAI0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize(state: State) -> State:\n",
        "  \"\"\"Categorize the customer query into Technical, Billing, or General Support\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "      \"categorize the following customer query into one of these categories: \"\n",
        "      \"Technical, Billing, Genral. Query:{query}\"\n",
        "  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  result_category = chain.invoke({\"query\": state[\"query\"]})\n",
        "  state[\"category\"] = result_category\n",
        "  return state\n",
        "\n",
        "def analyze_sentiment(state: State) -> State:\n",
        "  \"\"\"Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "  \"Analyze the sentiment of the following customer query. \"\n",
        "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  result_sentiment = chain.invoke({\"query\": state[\"query\"]})\n",
        "  state[\"sentiment\"] = result_sentiment\n",
        "  return state\n",
        "\n",
        "def handle_technical(state: State) -> State:\n",
        "  \"\"\"Handle technical queries\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "      \"provide a technical support response to the following customer query: {query}\"\n",
        "  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  result_technical = chain.invoke({\"query\": state[\"query\"]})\n",
        "  state[\"response\"]= result_technical\n",
        "  return state\n",
        "\n",
        "def handle_billing(state: State) -> State:\n",
        "    \"\"\"Provide a billing support response to the query.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Provide a billing support response to the following query: {query}\"\n",
        "    )\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    result_billing = chain.invoke({\"query\": state[\"query\"]})\n",
        "    state[\"response\"] = result_billing\n",
        "    return state\n",
        "\n",
        "\n",
        "def handle_general(state: State) -> State:\n",
        "  \"\"\"Provide a general support response to the query\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "      \"provide a general support response to the following query: {query}\"\n",
        "  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  result_general = chain.invoke({\"query\": state[\"query\"]})\n",
        "  state[\"response\"]= result_general\n",
        "  return state\n",
        "\n",
        "def escalate(state: State) -> State:\n",
        "    \"\"\"Escalate the query to a human agent due to negative sentiment.\"\"\"\n",
        "    return {\"response\": \"This query has been escalated to a human agent due to its negative sentiment.\"}\n",
        "\n",
        "def route_query(state: State) -> str:\n",
        "    \"\"\"Route the query based on its sentiment and category.\"\"\"\n",
        "    if state[\"sentiment\"] == \"Negative\":\n",
        "        return \"escalate\"\n",
        "    elif state[\"category\"] == \"Technical\":\n",
        "        return \"handle_technical\"\n",
        "    elif state[\"category\"] == \"Billing\":\n",
        "        return \"handle_billing\"\n",
        "    else:\n",
        "        return \"handle_general\""
      ],
      "metadata": {
        "id": "psmMwTvYAGLW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and Configure the Graph\n",
        "Here we set up the LangGraph, defining nodes and edges to create our customer support workflow.\n",
        "\n"
      ],
      "metadata": {
        "id": "WucRrR4rKXUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"categorize\", categorize)\n",
        "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
        "workflow.add_node(\"handle_technical\", handle_technical)\n",
        "workflow.add_node(\"handle_billing\", handle_billing)\n",
        "workflow.add_node(\"handle_general\", handle_general)\n",
        "workflow.add_node(\"escalate\", escalate)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(\"categorize\", \"analyze_sentiment\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"analyze_sentiment\",\n",
        "    route_query,\n",
        "    {\n",
        "        \"handle_technical\": \"handle_technical\",\n",
        "        \"handle_billing\": \"handle_billing\",\n",
        "        \"handle_general\": \"handle_general\",\n",
        "        \"escalate\": \"escalate\"\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"handle_technical\", END)\n",
        "workflow.add_edge(\"handle_billing\", END)\n",
        "workflow.add_edge(\"handle_general\", END)\n",
        "workflow.add_edge(\"escalate\", END)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"categorize\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "0uzvYuejCld-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Graph\n",
        "This cell generates and displays a visual representation of our LangGraph workflow.\n",
        "\n"
      ],
      "metadata": {
        "id": "EZfXJ2XXO1cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_customer_support(query: str) -> Dict[str, str]:\n",
        "    \"\"\"Process a customer query through the LangGraph workflow.\n",
        "\n",
        "    Args:\n",
        "        query (str): The customer's query\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary containing the query's category, sentiment, and response\n",
        "    \"\"\"\n",
        "    results = app.invoke({\"query\": query})\n",
        "    return {\n",
        "        \"category\": results[\"category\"],\n",
        "        \"sentiment\": results[\"sentiment\"],\n",
        "        \"response\": results[\"response\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "YO1B0iXarw2t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escalate\n",
        "\n",
        "query = \"My internet connection keeps dropping. Can you help?\"\n",
        "result = run_customer_support(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Sentiment: {result['sentiment']}\")\n",
        "print(f\"Response: {result['response']}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# handle_technical\n",
        "\n",
        "query = \"I need help talking to chatGPT\"\n",
        "result = run_customer_support(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Sentiment: {result['sentiment']}\")\n",
        "print(f\"Response: {result['response']}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# handle_billing\n",
        "\n",
        "query = \"where can i find my receipt?\"\n",
        "result = run_customer_support(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Sentiment: {result['sentiment']}\")\n",
        "print(f\"Response: {result['response']}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# handle_general\n",
        "\n",
        "query = \"What are your business hours?\"\n",
        "result = run_customer_support(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Category: {result['category']}\")\n",
        "print(f\"Sentiment: {result['sentiment']}\")\n",
        "print(f\"Response: {result['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IhnEB8QtnM7",
        "outputId": "faa346ab-9e4e-4a26-aef3-132e25803920"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: My internet connection keeps dropping. Can you help?\n",
            "Category: **Technical** \n",
            "\n",
            "This query is clearly about a technical issue with the customer's internet connection.  \n",
            "\n",
            "Sentiment: Negative \n",
            "\n",
            "Response: I understand you're experiencing internet connection drops, that can be very frustrating!  \n",
            "\n",
            "To help me pinpoint the issue, could you tell me a little more about what's happening?\n",
            "\n",
            "* **How often does your internet drop?** (Every few minutes, hours, etc.)\n",
            "* **Does it happen on all devices, or just one?**\n",
            "* **What type of internet connection do you have?** (Cable, DSL, Fiber, etc.)\n",
            "* **Have you made any recent changes to your network setup?** (New router, new devices, etc.)\n",
            "* **Are there any error messages you see when the connection drops?**\n",
            "\n",
            "Once I have a better understanding of the situation, I can offer more specific troubleshooting steps. \n",
            "\n",
            "In the meantime, some general things you can try are:\n",
            "\n",
            "* **Restart your modem and router.** This can often resolve temporary connectivity issues.\n",
            "* **Check your cables.** Make sure all cables are securely plugged in.\n",
            "* **Try a different device.** If the issue only affects one device, it may be a problem with that device.\n",
            "* **Run a speed test.** This can help determine if the issue is with your internet speed or your connection.\n",
            "\n",
            "\n",
            "Let's get your internet back up and running! \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Query: I need help talking to chatGPT\n",
            "Category: The query \"I need help talking to ChatGPT\" falls into the **General** category. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Technical:** This query doesn't involve specific technical issues with a product or service.\n",
            "* **Billing:**  There's no mention of invoices, payments, or account issues.\n",
            "* **General:** The user is seeking guidance on how to interact with a specific AI, which is a general inquiry about how to use a tool. \n",
            "\n",
            "\n",
            "Let me know if you have any other queries you'd like me to categorize! \n",
            "\n",
            "Sentiment: Neutral \n",
            "\n",
            "Response: I understand you're looking for help interacting with ChatGPT. \n",
            "\n",
            "To give you the best assistance, could you please tell me more about what kind of help you need? For example:\n",
            "\n",
            "* **Are you having technical difficulties accessing ChatGPT?** \n",
            "* **Are you unsure how to formulate your prompts for ChatGPT?**\n",
            "* **Are you getting unexpected or unsatisfactory results from ChatGPT?**\n",
            "* **Do you want to learn more about ChatGPT's capabilities and limitations?**\n",
            "\n",
            "The more information you provide, the better I can understand your situation and offer relevant advice. \n",
            "\n",
            "I can help with things like:\n",
            "\n",
            "* **Troubleshooting common ChatGPT issues**\n",
            "* **Providing tips for writing effective prompts**\n",
            "* **Explaining how ChatGPT works**\n",
            "* **Suggesting resources for learning more about AI chatbots**\n",
            "\n",
            "\n",
            "Let's work together to make your experience with ChatGPT more productive!  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Query: where can i find my receipt?\n",
            "Category: **Billing** \n",
            "\n",
            "This query is asking about a financial transaction (the receipt), which falls under the billing category. \n",
            "\n",
            "Sentiment: Neutral \n",
            "\n",
            "Response: I understand you're looking for your receipt. To help me find it for you, could you please provide some more information? \n",
            "\n",
            "For example:\n",
            "\n",
            "* **What is the purchase date?**\n",
            "* **What was purchased?**\n",
            "* **What payment method was used?**\n",
            "* **Did you purchase online or in-store?**\n",
            "\n",
            "Once I have these details, I can guide you to the right place to locate your receipt. \n",
            "\n",
            "\n",
            "Let me know, and I'll do my best to assist you! \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Query: What are your business hours?\n",
            "Category: The category for the query \"What are your business hours?\" is **General**. \n",
            "\n",
            "This is because the query is seeking information about the company's operational schedule, not specific technical support or billing inquiries. \n",
            "\n",
            "Sentiment: Neutral \n",
            "\n",
            "Response: Thank you for your interest! \n",
            "\n",
            "While I don't have traditional business hours as I'm always available,  my performance may be impacted by server availability and maintenance. \n",
            "\n",
            "If you need immediate assistance, please check our [website/help center] for frequently asked questions and resources. \n",
            "\n",
            "For any other inquiries, feel free to ask!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPk-KqJGt0S2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}